# -*- coding: utf-8 -*-
"""NLPAssignment2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D6XKHE5hmvvfUtb0hN-EdDNbaV5PJQE7

Data Exploration – Load the data and show first rows
"""

import pandas as pd

df = pd.read_excel("text_docs.xlsx")

print("Shape of dataset:", df.shape)
df.head()

"""Data Exploration – Show total rows and unique *documents*"""

print("Total rows:", len(df))
print("Unique documents:", df['document_id'].nunique())
print("Missing values per column:\n", df.isnull().sum())

"""We calculate the total number of rows, the number of unique documents, and check for missing values.

Identify preprocessing steps
"""

for i, text in enumerate(df['text'].head(5), 1):
    print(f"Document {i}: {text}\n")

"""We print a few sample texts to inspect what cleaning steps might be needed.

Task 2: Generate Topics Using LDA

Step 1: Preprocess the text

We will clean the text by:
	•	Lowercasing
	•	Removing punctuation and numbers
	•	Removing stopwords
	•	Tokenizing into words
"""

import nltk
import re
from nltk.corpus import stopwords

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

def preprocess(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)  # keep only letters
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]
    return tokens

df['tokens'] = df['text'].apply(preprocess)
df[['text', 'tokens']].head()

"""Task 2: Generate Topics Using LDA

Step 2: Create Document–Term Matrix

We will now build a dictionary and a document-term matrix (bag-of-words) using Gensim.
"""

!pip install gensim

from gensim import corpora

dictionary = corpora.Dictionary(df['tokens'])
corpus = [dictionary.doc2bow(text) for text in df['tokens']]

print("Number of unique words:", len(dictionary))
print("Sample document-term matrix (first document):", corpus[0])

"""Task 2: Generate Topics Using LDA

Step 3: Apply LDA model and extract topics
"""

from gensim.models import LdaModel

# Train LDA model
lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, random_state=42, passes=10)

# Display top 5 words for each topic
for idx, topic in lda_model.print_topics(num_words=5):
    print(f"Topic {idx+1}: {topic}")

"""The LDA model extracted 5 topics from the dataset. Each topic is represented by its most important words. For example, one topic relates to economy and business growth, another to renewable energy and technology, and another to climate/global issues. This shows that the model is successfully grouping documents into meaningful themes.

By,
Utkarsh Anand
"""